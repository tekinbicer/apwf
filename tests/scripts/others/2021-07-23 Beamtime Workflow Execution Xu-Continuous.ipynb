{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import logging\n",
    "import traceback\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "from globus_automate_client import (create_flows_client, graphviz_format, state_colors_for_log,\n",
    "                                    create_action_client,\n",
    "                                    create_flows_client)\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from funcx.serialize import FuncXSerializer\n",
    "\n",
    "# Flow Service Client ID\n",
    "CLIENT_ID = \"e6c75d97-532a-4c88-b031-8584a319fa3e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globus Online Endpoints\n",
    "src_endpoint = 'dd916908-0072-11e7-badc-22000b9a448b' # mona4 #'hostel' #aps/workstation\n",
    "dest_endpoint = '08925f04-569f-11e7-bef8-22000b9a448b' #'alcf#dtn_theta'\n",
    "\n",
    "# FuncX endpoint at ThetaGPU (ALCF) and Prisma (APS)\n",
    "theta_fx_endpoint = '5b5de98e-7701-4484-b03c-619a557c5fe6' # theta-ptycho-8w-1n-2cn #'2ab22e1f-4cf1-47e9-a40c-dd8c58b41d73' #theta-ptycho-8w-1n\n",
    "prisma_fx_endpoint = '37766683-85e2-49df-a1a7-6a070f566022' #mona4 (prisma-ptycho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncX function definition for remote ThetaGPU reconstruction call\n",
    "\n",
    "def ptycho(**data):\n",
    "    \"\"\"Test the ptycho tool\"\"\"\n",
    "    import os\n",
    "    import subprocess\n",
    "    import logging\n",
    "    from subprocess import PIPE\n",
    "\n",
    "    rec_ngpu = data['rec_ngpu']\n",
    "    wid = data['wid']\n",
    "    dataset_name = data['dataset_name']\n",
    "\n",
    "    log_file_name = \"/grand/hp-ptycho/bicer/20210723_workflow-Xu/logs/funcx-ptycho-{}-w{}-g{}.log\".format(dataset_name, wid, rec_ngpu)\n",
    "    logging.basicConfig(filename=log_file_name,\n",
    "                        filemode='a',\n",
    "                        format='%(asctime)s %(levelname)s %(message)s',\n",
    "                        level=logging.INFO,\n",
    "                        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    logging.info(\"Starting ptycho funcx function.\")\n",
    "\n",
    "    remote_log_file_name = \"/grand/hp-ptycho/bicer/20210723_workflow-Xu/logs/tike-wf-{}-w{}-g{}.log\".format(dataset_name, wid, rec_ngpu)\n",
    "\n",
    "    python_path = data['python_path']\n",
    "    script_path = data['script_path']\n",
    "\n",
    "    #recon. script parameters\n",
    "    ifpath = data['ifpath']\n",
    "    pospath = data['position_path']\n",
    "    probepath = data['probe_path']\n",
    "    ofpath = data['ofpath']\n",
    "    rec_alg = data['rec_alg']\n",
    "    rec_nmodes = data['rec_nmodes']\n",
    "    rec_niter = data['rec_niter']\n",
    "    rec_output_freq = data['rec_output_freq']\n",
    "    rec_recover_psi = '--recover-psi' if (('rec_recover_psi' in data) and data['rec_recover_psi']) else ''\n",
    "    rec_recover_probe = '--recover-probe' if (('rec_recover_probe' in data) and data['rec_recover_probe']) else ''\n",
    "    rec_recover_positions = '--recover-positions' if (('rec_recover_positions' in data) and data['rec_recover_positions']) else ''\n",
    "    rec_model = data['rec_model']\n",
    "    rec_use_mpi = '--use-mpi' if (('rec_use_mpi' in data) and data['rec_use_mpi']) else ''\n",
    "    rec_overwrite = '--overwrite' if (('rec_overwrite' in data) and data['rec_overwrite']) else ''\n",
    "    rec_auto_pin = '--auto-pin' if (('rec_auto_pin' in data) and data['rec_auto_pin']) else ''\n",
    "    rec_gpu_id = data['rec_gpu_id']\n",
    "    rec_log_filename = remote_log_file_name\n",
    "\n",
    "    try:\n",
    "        os.mkdir(ofpath)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    cmd = f\"{python_path} {script_path} --algorithm={rec_alg} --nmodes={rec_nmodes} --niter={rec_niter} --output-freq={rec_output_freq} {rec_recover_psi} {rec_recover_probe} {rec_recover_positions} --model={rec_model} --ngpu={rec_ngpu} {rec_use_mpi} --ifile='{ifpath}' --position-path={pospath} --probe-path={probepath} {rec_overwrite} {rec_auto_pin} --gpu-id={rec_gpu_id} --folder='{ofpath}' --log-file='{rec_log_filename}'\"\n",
    "    logging.info(f\"Running command: {cmd}\")\n",
    "\n",
    "    try:\n",
    "        res = subprocess.run(cmd, stdout=PIPE, stderr=PIPE,\n",
    "                             shell=True, executable='/bin/bash')\n",
    "    except:\n",
    "        pass\n",
    "    outstr = f\"{res.stdout}\"\n",
    "    return outstr\n",
    "\n",
    "func_ptycho_uuid = fxc.register_function(ptycho)\n",
    "print(func_ptycho_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncX function definition for remote DAQ machine directory calls\n",
    "def get_folder_paths(path):\n",
    "    import glob\n",
    "    import re\n",
    "\n",
    "    return sorted(glob.glob(path, recursive=False),\n",
    "                key = lambda v : int(re.search(r\"(\\d+)\" , v[len(v)-\"\".join(reversed(v)).index('/'):]).group(0)))\n",
    "\n",
    "\n",
    "def get_file_paths(path):\n",
    "    import glob\n",
    "    import re\n",
    "\n",
    "    return sorted(glob.glob(path, recursive=False),\n",
    "                key = lambda v : int(re.search(r\"(\\d+)\" , v[len(v)-\"\".join((reversed(v))).index('/'):v.index('.')]).group(0)))\n",
    "\n",
    "fx_func_get_file_paths_uuid = fxc.register_function(get_file_paths)\n",
    "fx_func_get_folder_paths_uuid = fxc.register_function(get_folder_paths)\n",
    "print(fx_func_get_file_paths_uuid)\n",
    "print(fx_func_get_folder_paths_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local helper functions for keeping track of the active scans\n",
    "def append_activated_iids(data, csv_path='/home/beams/TBICER/logs/activated_iids.csv'):\n",
    "    print(\"adding row to activated: {}\".format(data))\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for row in data:\n",
    "            writer.writerow([row, datetime.datetime.now()])\n",
    "            \n",
    "def read_activated_iids(csv_path='/home/beams/TBICER/logs/activated_iids.csv'):\n",
    "    vals = []\n",
    "    with open(csv_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            vals.append(row)\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globus Automate flow definition (Gladier will cleanup this)\n",
    "\n",
    "flow_definition = {\n",
    "  \"Comment\": \"Ptychographic reconstruction workflow\",\n",
    "  \"StartAt\": \"Transfer\",\n",
    "  \"States\": {\n",
    "    \"Transfer\": {\n",
    "      \"Comment\": \"Initial transfer\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://actions.automate.globus.org/transfer/transfer\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/actions.globus.org/transfer/transfer\",\n",
    "      \"Parameters\": {\n",
    "        \"source_endpoint_id.$\": \"$.input.source_endpoint\",\n",
    "        \"destination_endpoint_id.$\": \"$.input.dest_endpoint\",\n",
    "        \"transfer_items\": [\n",
    "          {\n",
    "            \"source_path.$\": \"$.input.source_path\",\n",
    "            \"destination_path.$\": \"$.input.dest_path\",\n",
    "            \"recursive\": True\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Transfer1Result\",\n",
    "      \"WaitTime\": 14400,\n",
    "      \"Next\": \"PosTransfer\"\n",
    "    },\n",
    "    \"PosTransfer\": {\n",
    "      \"Comment\": \"Transfer position file\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://actions.automate.globus.org/transfer/transfer\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/actions.globus.org/transfer/transfer\",\n",
    "      \"Parameters\": {\n",
    "        \"source_endpoint_id.$\": \"$.input.source_endpoint\",\n",
    "        \"destination_endpoint_id.$\": \"$.input.dest_endpoint\",\n",
    "        \"transfer_items\": [\n",
    "          {\n",
    "            \"source_path.$\": \"$.input.source_pos_path\",\n",
    "            \"destination_path.$\": \"$.input.dest_pos_path\",\n",
    "            \"recursive\": False\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Transfer1Result\",\n",
    "      \"WaitTime\": 14400,\n",
    "      \"Next\": \"Analyze\"\n",
    "    },\n",
    "    \"Analyze\": {\n",
    "      \"Comment\": \"Run a funcX function\",\n",
    "      \"Type\": \"Action\",\n",
    "      #\"ActionUrl\": \"https://api.funcx.org/automate\",\n",
    "        \"ActionUrl\": \"https://automate.funcx.org\",\n",
    "      #\"ActionScope\": \"https://auth.globus.org/scopes/facd7ccc-c5f4-42aa-916b-a0e270e2c2a9/automate2\",\n",
    "        \"ActionScope\": \"https://auth.globus.org/scopes/b3db7e59-a6f1-4947-95c2-59d6b7a70f8c/action_all\",\n",
    "      \"Parameters\": {\n",
    "          \"tasks\": [{\n",
    "            \"endpoint.$\": \"$.input.fx_ep\",\n",
    "            \"function.$\": \"$.input.fx_id\",\n",
    "            \"payload.$\": \"$.input.params\"\n",
    "        }]\n",
    "      },\n",
    "      \"ResultPath\": \"$.AnalyzeResult\",\n",
    "      \"WaitTime\": 14400,\n",
    "      \"Next\": \"Transfer2\"\n",
    "    },\n",
    "    \"Transfer2\": {\n",
    "      \"Comment\": \"Return transfer\",\n",
    "      \"Type\": \"Action\",\n",
    "      \"ActionUrl\": \"https://actions.automate.globus.org/transfer/transfer\",\n",
    "      \"ActionScope\": \"https://auth.globus.org/scopes/actions.globus.org/transfer/transfer\",\n",
    "      \"Parameters\": {\n",
    "        \"source_endpoint_id.$\": \"$.input.dest_endpoint\",\n",
    "        \"destination_endpoint_id.$\": \"$.input.source_endpoint\",\n",
    "        \"transfer_items\": [\n",
    "          {\n",
    "            \"source_path.$\": \"$.input.result_path\",\n",
    "            \"destination_path.$\": \"$.input.source_result_path\",\n",
    "            \"recursive\": True #False\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"ResultPath\": \"$.Transfer2Result\",\n",
    "      \"WaitTime\": 14400,\n",
    "      \"End\": True\n",
    "    },\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a flow with the above flow definition ###\n",
    "flows_client = create_flows_client(CLIENT_ID)\n",
    "flow = flows_client.deploy_flow(flow_definition, validate_schema=False, title=\"Simple ptycho data analysis flow\")\n",
    "flow_id = flow['id']\n",
    "flow_scope = flow['globus_auth_scope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_name = \"battery\"\n",
    "q1 = deque()\n",
    "log_file_name = \"/home/beams/TBICER/logs/20210723_workflow-Xu/funcx-ptycho-wf-{}.log\".format(dataset_name)\n",
    "logging.basicConfig(filename=log_file_name,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logging.INFO,\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ### Start of folder generation ###\n",
    "    src_wf_root_path = '/mnt/micdata2/velociprobe/2021-2/Xu'\n",
    "    src_input_folder_prefix = \"ptycho-test\"\n",
    "    src_input_pos_folder_prefix = \"positions\"\n",
    "    src_output_folder_prefix = \"wf-recons-test-i100\"\n",
    "\n",
    "    dest_wf_root_path = '/grand/hp-ptycho/bicer/20210723_workflow-Xu'\n",
    "    dest_input_folder_prefix = \"input\"\n",
    "    dest_output_folder_prefix = \"output\"\n",
    "\n",
    "    add_larger_than = 999\n",
    "    \n",
    "    # Get the activated iids\n",
    "    activated_iids_rows = read_activated_iids()\n",
    "    activated_iids = []\n",
    "    for r in activated_iids_rows:\n",
    "        activated_iids.append(r[0])\n",
    "\n",
    "    # Get the remote folders at source input folder\n",
    "    src_input_folder_paths_regex = f\"{src_wf_root_path}/{src_input_folder_prefix}/*\"\n",
    "    print(src_input_folder_paths_regex)\n",
    "    rid = fxc.run(src_input_folder_paths_regex,\n",
    "                  endpoint_id=prisma_fx_endpoint,\n",
    "                  function_id=fx_func_get_folder_paths_uuid)\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            src_input_folder_paths = fxc.get_result(rid)\n",
    "            print(src_input_folder_paths)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            print(\"Result is not ready:{}\".format(sys.exc_info()[0]))\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    iids = []\n",
    "    for src_input_folder_path in src_input_folder_paths:\n",
    "        #print(src_input_folder_path)\n",
    "        iid = re.findall(r'\\d+', src_input_folder_path)\n",
    "        if int(iid[-1]) > add_larger_than: \n",
    "            #print(\"id is being added:{}\".format(int(iid[-1])))\n",
    "            iids.append(iid[-1])\n",
    "        else: continue\n",
    "\n",
    "\n",
    "    # Get the remote folders at source output folder\n",
    "    src_output_folder_paths_regex = f\"{src_wf_root_path}/{src_output_folder_prefix}/*\"\n",
    "    rid = fxc.run(src_output_folder_paths_regex,\n",
    "                  endpoint_id=prisma_fx_endpoint,\n",
    "                  function_id=fx_func_get_folder_paths_uuid)\n",
    "    while True:\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            ex_src_output_folder_paths = fxc.get_result(rid)\n",
    "            #print(ex_src_output_folder_paths)\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            print(\"Result is not ready:{}\".format(sys.exc_info()[0]))\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    oiids = []\n",
    "    for ex_src_output_folder_path in ex_src_output_folder_paths:\n",
    "        oiid = re.findall(r'\\d+', ex_src_output_folder_path)\n",
    "        if int(oiid[-1]) > add_larger_than: \n",
    "            #print(\"id is being added:{}\".format(int(oiid[-1])))\n",
    "            oiids.append(oiid[-1])\n",
    "        else: continue\n",
    "\n",
    "    # Find the iids that need to be processed\n",
    "    diff_iids = []\n",
    "    for iid in iids:\n",
    "        if (int(iid)>add_larger_than) and (iid not in oiids) and (iid not in activated_iids): \n",
    "            diff_iids.append(iid) # process only these\n",
    "    \n",
    "    # If there is no file to be processed sleep 1 second and recheck \n",
    "    if(len(diff_iids)==0):\n",
    "        print(\"There is no folder to be processed, sleeping 1 secs.\")\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "    #print(\"diff_iids:{}\\niids:{}\\noiids:{}\\nactivated_iids:{}\".format(diff_iids, iids, oiids,activated_iids))\n",
    "    \n",
    "    \n",
    "    #print(\"Creating works for these ids: {}\\n\".format(diff_iids))\n",
    "    fsrc_input_folder_paths = []\n",
    "    src_input_pos_files = []\n",
    "    src_output_folder_paths = []\n",
    "    dest_output_folder_paths = []\n",
    "    dest_input_folder_paths = []\n",
    "    dest_input_pos_files = []\n",
    "    iids = []\n",
    "    for src_input_folder_path in src_input_folder_paths[:-1]:\n",
    "        #print(src_input_folder_path)\n",
    "        iid = re.findall(r'\\d+', src_input_folder_path)\n",
    "        #if (int(iid[-1]) <= add_larger_than) or (iid[-1] in oiids): continue\n",
    "        # Skip if iid is already activated or processed\n",
    "        if (iid[-1] not in diff_iids): continue\n",
    "        iids.append(iid[-1])\n",
    "        fsrc_input_folder_paths.append(src_input_folder_path)\n",
    "        src_input_pos_files.append(f\"{src_wf_root_path}/{src_input_pos_folder_prefix}/fly{iid[-1]}_0.txt\")\n",
    "        src_output_folder_path = f\"{src_wf_root_path}/{src_output_folder_prefix}/{iid[-1]}\"\n",
    "        src_output_folder_paths.append(src_output_folder_path)\n",
    "        dest_input_folder_path = f\"{dest_wf_root_path}/{dest_input_folder_prefix}/{iid[-1]}\"\n",
    "        dest_input_folder_paths.append(dest_input_folder_path)\n",
    "        dest_input_pos_files.append(f\"{dest_input_folder_path}/fly{iid[-1]}_0.txt\")\n",
    "        dest_output_folder_path = f\"{dest_wf_root_path}/{dest_output_folder_prefix}/{iid[-1]}\"\n",
    "        dest_output_folder_paths.append(dest_output_folder_path)\n",
    "    src_input_folder_paths = fsrc_input_folder_paths\n",
    "    #print(len(src_input_folder_paths))\n",
    "    # src_input_folder_paths: diffraction patterh files to be processed @ APS\n",
    "    # src_output_folder_paths: folders for reconstrcuted images after processing @ APS\n",
    "    # dest_input_folder_paths: diffraction patterh files to be processed @ ALCF\n",
    "    # dest_output_folder_paths: folders for reconstrcuted images after processing @ ALCF\n",
    "\n",
    "    iids.reverse()\n",
    "    src_input_folder_paths.reverse()\n",
    "    src_input_pos_files.reverse()\n",
    "    src_output_folder_paths.reverse()\n",
    "    dest_input_folder_paths.reverse()\n",
    "    dest_input_pos_files.reverse()\n",
    "    dest_output_folder_paths.reverse()\n",
    "\n",
    "    for (iid, src_input_folder_path, src_input_pos_file, src_output_folder_path, dest_input_folder_path, dest_input_pos_file, dest_output_folder_path ) in zip(iids, src_input_folder_paths, src_input_pos_files, src_output_folder_paths, dest_input_folder_paths, dest_input_pos_files, dest_output_folder_paths):\n",
    "        print(f\"{iid}: Source input folder: {src_input_folder_path}; Source position file: {src_input_pos_file}; Source output folder: {src_output_folder_path}\")\n",
    "        print(f\"Dest. input folder: {dest_input_folder_path}; Dest. position file: {dest_input_pos_file}; Dest. output folder: {dest_output_folder_path}\")\n",
    "        print()\n",
    "    \n",
    "    if(len(iids)>0):\n",
    "        print(\"diff_iids:{}\\niids:{}\\noiids:{}\".format(diff_iids, iids, oiids))\n",
    "    ### End of folder generation ###\n",
    "    \n",
    "      \n",
    "    ### Ptycho recon params setting up ###\n",
    "    script_path = '/home/bicer/projects/tike/scripts/tike-pinned-ptycho-wf.py'\n",
    "    #python_path = \"/home/bicer/projects/tyler/bin/python\"\n",
    "    python_path = \"/home/bicer/miniconda3/envs/ptycho/bin/python\"\n",
    "\n",
    "    probe_path = '/grand/hp-ptycho/bicer/20210723_workflow-Xu/probes/velociprobe-probe.npy'\n",
    "\n",
    "    rec_alg = 'lstsq_grad'\n",
    "    rec_nmodes = 1\n",
    "    rec_upd_pos = False\n",
    "    rec_niter = 100\n",
    "    rec_output_freq = 20\n",
    "    rec_recover_psi = True\n",
    "    rec_recover_probe= True\n",
    "    rec_recover_positions = False\n",
    "    rec_model = 'gaussian'\n",
    "    rec_ngpu = 1\n",
    "    rec_use_mpi = False\n",
    "    rec_overwrite = True\n",
    "    rec_auto_pin = True\n",
    "\n",
    "    nworkers_per_node = 8\n",
    "\n",
    "    flow_inputs = []\n",
    "    gcounter = 0\n",
    "    for (iid, src_input_folder_path, src_input_pos_file, src_output_folder_path,\n",
    "         dest_input_folder_path, dest_input_pos_file, dest_output_folder_path ) in zip(iids,\n",
    "        src_input_folder_paths, src_input_pos_files, src_output_folder_paths,\n",
    "        dest_input_folder_paths, dest_input_pos_files, dest_output_folder_paths):\n",
    "\n",
    "        rec_gpu_id = gcounter%nworkers_per_node\n",
    "\n",
    "        flow_input = {\n",
    "            \"iid\" : iid,\n",
    "            \"input\": {\n",
    "                \"source_endpoint\": f\"{src_endpoint}\",\n",
    "                \"source_path\": f\"{src_input_folder_path}/\",\n",
    "                \"source_pos_path\": f\"{src_input_pos_file}\",\n",
    "                \"dest_endpoint\": dest_endpoint,\n",
    "                \"dest_path\": f\"{dest_input_folder_path}/\",\n",
    "                \"dest_pos_path\": dest_input_pos_file,\n",
    "\n",
    "                \"result_path\": f\"{dest_output_folder_path}\",\n",
    "                \"source_result_path\": f\"{src_output_folder_path}\",\n",
    "                \"fx_ep\": f\"{theta_fx_endpoint}\",\n",
    "                \"fx_id\": f\"{func_ptycho_uuid}\",\n",
    "                \"params\": {'ifpath': f\"{dest_input_folder_path}/fly{iid}_master.h5\",\n",
    "                           'ofpath': f\"{dest_output_folder_path}/\",\n",
    "                           'position_path': dest_input_pos_file,\n",
    "                           'probe_path': probe_path,\n",
    "                           'script_path': script_path,\n",
    "                           'python_path': python_path,\n",
    "                           'rec_alg': rec_alg,\n",
    "                           'rec_nmodes': rec_nmodes,\n",
    "                           'rec_upd_pos': rec_upd_pos,\n",
    "                           'rec_niter': rec_niter,\n",
    "                           'rec_output_freq': rec_output_freq,\n",
    "                           'rec_recover_psi': rec_recover_psi,\n",
    "                           'rec_recover_probe': rec_recover_probe,\n",
    "                           'rec_recover_positions': rec_recover_positions,\n",
    "                           'rec_model': rec_model,\n",
    "                           'rec_ngpu': rec_ngpu,\n",
    "                           'rec_use_mpi': rec_use_mpi,\n",
    "                           'rec_overwrite': rec_overwrite,\n",
    "                           'rec_auto_pin': rec_auto_pin,\n",
    "                           'rec_gpu_id':rec_gpu_id,\n",
    "                           'dataset_name': dataset_name,\n",
    "                           'wid':gcounter}\n",
    "            }\n",
    "        }\n",
    "        gcounter=gcounter+1\n",
    "        flow_inputs.append(flow_input)\n",
    "        ### End of parameter setup\n",
    "    \n",
    "    for finputs in flow_inputs:\n",
    "        print(\"Flow input iid: {}\".format(finputs['iid']))\n",
    "    \n",
    "    print(\"Number of flows to be generated: {}\".format(len(flow_inputs)))\n",
    "    \n",
    "    ### Initiate Flow ###\n",
    "    nnodes = 2\n",
    "    nworkers_per_node = 8\n",
    "\n",
    "    nflows = len(flow_inputs)\n",
    "\n",
    "    for i in range(nflows):\n",
    "        flow_action = flows_client.run_flow(flow_id, flow_scope, flow_inputs[i])\n",
    "        q1.append(flow_action)\n",
    "        append_activated_iids([flow_inputs[i]['iid']])\n",
    "        lstr=f\"Flow {i} initiated and added to q1: {flow_action['action_id']}\"\n",
    "        logging.info(lstr)\n",
    "        print(lstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel all flows\n",
    "for flow_action in q1:\n",
    "    flows_client.flow_action_cancel(flow_id, flow_scope, flow_action['action_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
