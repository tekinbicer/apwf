{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import re\n",
    "import logging\n",
    "import yaml\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "from apwf.tools import fx_comp_helper, fx_daq_helper, executor_helper \n",
    "from apwf.flows import automate_helper\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from globus_automate_client import create_flows_client\n",
    "\n",
    "\n",
    "configfile = f\"{os.getcwd()}/ptycho_wf_config.yml\"\n",
    "wf_config= yaml.safe_load(open(configfile))\n",
    "\n",
    "# Log configuration for both stdout and file\n",
    "log_file_name = f\"{wf_config['executor']['log_folder_path']}/funcx-ptycho-wf-{wf_config['flow']['sample_name']}.log\"\n",
    "logFormatter = logging.Formatter(fmt='%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)\n",
    "\n",
    "fileHandler = logging.FileHandler(filename=log_file_name, mode='a')\n",
    "fileHandler.setFormatter(logFormatter)\n",
    "fileHandler.setLevel(logging.INFO)\n",
    "rootLogger.addHandler(fileHandler)\n",
    "\n",
    "consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "consoleHandler.setFormatter(logFormatter)\n",
    "consoleHandler.setLevel(logging.INFO)\n",
    "rootLogger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globus Online Endpoints\n",
    "src_endpoint = wf_config['globus_endpoints']['aps_mona4_gcp']\n",
    "dest_endpoint = wf_config['globus_endpoints']['alcf_theta']\n",
    "\n",
    "# FuncX endpoint at ThetaGPU (ALCF) and Prisma (APS)\n",
    "compute_fx_endpoint = wf_config['funcx_endpoints']['alcf_polaris_gpu']\n",
    "daq_fx_endpoint = wf_config['funcx_endpoints']['aps_mona4_daq']\n",
    "\n",
    "print(compute_fx_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register setup functions to funcx service\n",
    "daq_wf_fxid = fxc.register_function(fx_daq_helper.daq_wf_prepare)\n",
    "comp_wf_fxid = fxc.register_function(fx_comp_helper.comp_wf_prepare)\n",
    "\n",
    "## Prepare workflow environment ##\n",
    "# Executor\n",
    "res = executor_helper.executor_wf_prepare(wf_config['executor']['activated_iids_file_path'],\n",
    "                                          wf_config['executor']['log_folder_path'],\n",
    "                                          create_activated_iid_file=True, create_log_folder=True, \n",
    "                                          cleanup_activated_iid_file=True, cleanup_log_folder=False)\n",
    "if res != 0: logging.error(f\"Unable to setup executor folders/files: {res}\")\n",
    "else: logging.info(\"Executor folders/files are ready.\")\n",
    "\n",
    "# Data acquisition\n",
    "rid = fxc.run(f\"{wf_config['flow']['source']['root_folder_path']}/{wf_config['flow']['source']['input_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['source']['root_folder_path']}/{wf_config['flow']['source']['input_position_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['source']['root_folder_path']}/{wf_config['flow']['source']['output_folder_prefix']}\",\n",
    "              probe_file_path=None, create_output_folder=True, cleanup_output_folder=True,\n",
    "              endpoint_id=daq_fx_endpoint, function_id=daq_wf_fxid)\n",
    "res = automate_helper.fx_get_result(rid, fxc)\n",
    "if res != 0: logging.error(f\"Unable to setup data acquisition machine folders/files: {res}\")\n",
    "else: logging.info(\"Data acquisition machine's folders/files are ready.\")\n",
    "\n",
    "# Compute machine\n",
    "rid = fxc.run(f\"{wf_config['flow']['destination']['root_folder_path']}/{wf_config['flow']['destination']['input_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['destination']['root_folder_path']}/{wf_config['flow']['destination']['output_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['task']['executable']['params']['log_folder_path']}\",\n",
    "              create_input_folder=True, create_output_folder=True, create_log_folder=True, \n",
    "              cleanup_input_folder=True, cleanup_output_folder=True, cleanup_log_folder=False,\n",
    "              endpoint_id=compute_fx_endpoint, function_id=comp_wf_fxid)\n",
    "res = automate_helper.fx_get_result(rid, fxc)\n",
    "if res != 0: logging.error(f\"Unable to setup compute machine folders/files: {res}\")\n",
    "else: logging.info(\"Compute machines' folders/files are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncX function definition for remote Polaris GPU reconstruction call\n",
    "func_ptycho_uuid = fxc.register_function(fx_comp_helper.ptycho_func)\n",
    "print(func_ptycho_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncX function definition for remote DAQ machine directory calls\n",
    "fx_func_get_file_paths_uuid = fxc.register_function(fx_daq_helper.get_file_paths)\n",
    "fx_func_get_folder_paths_uuid = fxc.register_function(fx_daq_helper.get_folder_paths)\n",
    "print(fx_func_get_file_paths_uuid)\n",
    "print(fx_func_get_folder_paths_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globus Automate flow definition\n",
    "flow_definition = automate_helper.ptycho_flow_definition\n",
    "\n",
    "# Create a flow with the above flow definition\n",
    "flows_client = create_flows_client()\n",
    "flow = flows_client.deploy_flow(flow_definition, input_schema={}, title=wf_config['flow']['title'])\n",
    "flow_id = flow['id']\n",
    "flow_scope = flow['globus_auth_scope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_config = wf_config['flow']['source']\n",
    "dest_config = wf_config['flow']['destination']\n",
    "task_config = wf_config['flow']['task']\n",
    "exec_params_config = task_config['executable']['params']\n",
    "\n",
    "wfc = executor_helper.EConfigs(src_config, dest_config, wf_config['flow']['only_larger_than_scanid'])\n",
    "\n",
    "while True:\n",
    "    # Get the remote folders at source input folder\n",
    "    src_input_folder_paths_regex = f\"{wfc.src_wf_root_path}/{wfc.src_input_folder_prefix}/*\"\n",
    "    rid = fxc.run(src_input_folder_paths_regex,\n",
    "                  endpoint_id=daq_fx_endpoint,\n",
    "                  function_id=fx_func_get_folder_paths_uuid)\n",
    "    src_input_folder_paths = automate_helper.fx_get_result(rid, fxc, delay=wf_config['funcx_req_delay'])\n",
    "\n",
    "    # Get the remote folders at source output folder\n",
    "    src_output_folder_paths_regex = f\"{wfc.src_wf_root_path}/{wfc.src_output_folder_prefix}/*\"\n",
    "    rid = fxc.run(src_output_folder_paths_regex,\n",
    "                  endpoint_id=daq_fx_endpoint,\n",
    "                  function_id=fx_func_get_folder_paths_uuid)\n",
    "    ex_src_output_folder_paths = automate_helper.fx_get_result(rid, fxc, delay=wf_config['funcx_req_delay'])\n",
    "\n",
    "    # Get the activated iids and find the iids that need to be processed\n",
    "    activated_iids = executor_helper.read_activated_iids(wf_config['executor']['activated_iids_file_path'])\n",
    "    diff_iids = executor_helper.get_unprocessed_iids(activated_iids, src_input_folder_paths, ex_src_output_folder_paths, wfc.add_larger_than)\n",
    "    \n",
    "    # If there is no iid/scan to be processed sleep, and then re-check \n",
    "    if(len(diff_iids)==0):\n",
    "        logging.debug(f\"There is no folder to be processed, \"\n",
    "                      f\"sleeping {wf_config['data_generation_delay']} secs.\")\n",
    "        time.sleep(wf_config['data_generation_delay'])\n",
    "        continue\n",
    "    \n",
    "    # There are scans to be processed, generate paths\n",
    "    paths = executor_helper.WFPaths(wfc, src_input_folder_paths, diff_iids).plist\n",
    "     \n",
    "    # Generate flow inputs according to the paths and other configuration info.\n",
    "    flow_inputs = executor_helper.WFFlowsInputs(src_endpoint, dest_endpoint, compute_fx_endpoint, \n",
    "                                            func_ptycho_uuid, task_config, exec_params_config, \n",
    "                                            wf_config['flow']['sample_name'], paths).filist\n",
    "\n",
    "    \n",
    "    logging.info(f\"Flows to be generated: {[finputs['iid'] for finputs in flow_inputs]}\\n\"\n",
    "                 f\"Total number of flows to be generated: {len(flow_inputs)}\")\n",
    "    \n",
    "    ### Initiate Flow ###\n",
    "    q1 = deque()\n",
    "    for i in range(len(flow_inputs)):\n",
    "        flow_action = flows_client.run_flow(flow_id, flow_scope, flow_inputs[i])\n",
    "        q1.append(flow_action)\n",
    "        executor_helper.append_activated_iids([flow_inputs[i]['iid']], wf_config['executor']['activated_iids_file_path'])\n",
    "        logging.info(f\"Flow {i} initiated and added to q1: {flow_action['action_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel all flows\n",
    "for flow_action in q1:\n",
    "    flows_client.flow_action_cancel(flow_id, flow_scope, flow_action['action_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
