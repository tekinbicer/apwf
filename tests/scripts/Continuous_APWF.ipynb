{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import re\n",
    "import logging\n",
    "import yaml\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "from apwf.tools import fx_comp_helper, fx_daq_helper, executor_helper \n",
    "from apwf.flows import automate_helper\n",
    "\n",
    "from funcx.sdk.client import FuncXClient\n",
    "from globus_automate_client import create_flows_client\n",
    "\n",
    "\n",
    "configfile = f\"{os.getcwd()}/ptycho_wf_config.yml\"\n",
    "wf_config= yaml.safe_load(open(configfile))\n",
    "\n",
    "# Log configuration for both stdout and file\n",
    "log_file_name = f\"{wf_config['executor']['log_folder_path']}/funcx-ptycho-wf-{wf_config['flow']['sample_name']}.log\"\n",
    "logFormatter = logging.Formatter(fmt='%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)\n",
    "\n",
    "fileHandler = logging.FileHandler(filename=log_file_name, mode='a')\n",
    "fileHandler.setFormatter(logFormatter)\n",
    "fileHandler.setLevel(logging.INFO)\n",
    "rootLogger.addHandler(fileHandler)\n",
    "\n",
    "consoleHandler = logging.StreamHandler(sys.stdout)\n",
    "consoleHandler.setFormatter(logFormatter)\n",
    "consoleHandler.setLevel(logging.INFO)\n",
    "rootLogger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globus Online Endpoints\n",
    "src_endpoint = wf_config['globus_endpoints']['aps_mona4_gcp']\n",
    "dest_endpoint = wf_config['globus_endpoints']['alcf_theta']\n",
    "\n",
    "# FuncX endpoint at ThetaGPU (ALCF) and Prisma (APS)\n",
    "compute_fx_endpoint = wf_config['funcx_endpoints']['alcf_polaris_gpu']\n",
    "daq_fx_endpoint = wf_config['funcx_endpoints']['aps_mona4_daq']\n",
    "\n",
    "print(compute_fx_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxc = FuncXClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register setup functions to funcx service\n",
    "daq_wf_fxid = fxc.register_function(fx_daq_helper.daq_wf_prepare)\n",
    "comp_wf_fxid = fxc.register_function(fx_comp_helper.comp_wf_prepare)\n",
    "\n",
    "## Prepare workflow environment ##\n",
    "# Executor\n",
    "res = executor_helper.executor_wf_prepare(wf_config['executor']['activated_iids_file_path'],\n",
    "                                          wf_config['executor']['log_folder_path'],\n",
    "                                          create_activated_iid_file=True, create_log_folder=True, \n",
    "                                          cleanup_activated_iid_file=True, cleanup_log_folder=False)\n",
    "if res != 0: logging.error(f\"Unable to setup executor folders/files: {res}\")\n",
    "else: logging.info(\"Executor folders/files are ready.\")\n",
    "\n",
    "# Data acquisition\n",
    "rid = fxc.run(f\"{wf_config['flow']['source']['root_folder_path']}/{wf_config['flow']['source']['input_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['source']['root_folder_path']}/{wf_config['flow']['source']['input_position_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['source']['root_folder_path']}/{wf_config['flow']['source']['output_folder_prefix']}\",\n",
    "              probe_file_path=None, create_output_folder=True, cleanup_output_folder=True,\n",
    "              endpoint_id=daq_fx_endpoint, function_id=daq_wf_fxid)\n",
    "res = automate_helper.fx_get_result(rid, fxc)\n",
    "if res != 0: logging.error(f\"Unable to setup data acquisition machine folders/files: {res}\")\n",
    "else: logging.info(\"Data acquisition machine's folders/files are ready.\")\n",
    "\n",
    "# Compute machine\n",
    "rid = fxc.run(f\"{wf_config['flow']['destination']['root_folder_path']}/{wf_config['flow']['destination']['input_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['destination']['root_folder_path']}/{wf_config['flow']['destination']['output_folder_prefix']}\",\n",
    "              f\"{wf_config['flow']['task']['executable']['params']['log_folder_path']}\",\n",
    "              create_input_folder=True, create_output_folder=True, create_log_folder=True, \n",
    "              cleanup_input_folder=True, cleanup_output_folder=True, cleanup_log_folder=False,\n",
    "              endpoint_id=compute_fx_endpoint, function_id=comp_wf_fxid)\n",
    "res = automate_helper.fx_get_result(rid, fxc)\n",
    "if res != 0: logging.error(f\"Unable to setup compute machine folders/files: {res}\")\n",
    "else: logging.info(\"Compute machines' folders/files are ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncX function definition for remote Polaris GPU reconstruction call\n",
    "func_ptycho_uuid = fxc.register_function(fx_comp_helper.ptycho_func)\n",
    "print(func_ptycho_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FuncX function definition for remote DAQ machine directory calls\n",
    "fx_func_get_file_paths_uuid = fxc.register_function(fx_daq_helper.get_file_paths)\n",
    "fx_func_get_folder_paths_uuid = fxc.register_function(fx_daq_helper.get_folder_paths)\n",
    "print(fx_func_get_file_paths_uuid)\n",
    "print(fx_func_get_folder_paths_uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globus Automate flow definition\n",
    "flow_definition = automate_helper.ptycho_flow_definition\n",
    "\n",
    "# Create a flow with the above flow definition\n",
    "flows_client = create_flows_client()\n",
    "flow = flows_client.deploy_flow(flow_definition, input_schema={}, title=wf_config['flow']['title'])\n",
    "flow_id = flow['id']\n",
    "flow_scope = flow['globus_auth_scope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src_config = wf_config['flow']['source']\n",
    "dest_config = wf_config['flow']['destination']\n",
    "task_config = wf_config['flow']['task']\n",
    "exec_params_config = task_config['executable']['params']\n",
    "\n",
    "while True:\n",
    "    ### Start of folder generation ###\n",
    "    src_wf_root_path = src_config['root_folder_path']\n",
    "    src_input_folder_prefix = src_config['input_folder_prefix']\n",
    "    src_input_pos_folder_prefix = src_config['input_position_folder_prefix']\n",
    "    src_output_folder_prefix = src_config['output_folder_prefix']\n",
    "\n",
    "    dest_wf_root_path = dest_config['root_folder_path']\n",
    "    dest_input_folder_prefix = dest_config['input_folder_prefix']\n",
    "    dest_output_folder_prefix = dest_config['output_folder_prefix']\n",
    "\n",
    "    add_larger_than = wf_config['flow']['only_larger_than_scanid']\n",
    "    \n",
    "    # Get the activated iids\n",
    "    activated_iids_rows = executor_helper.read_activated_iids(wf_config['executor']['activated_iids_file_path'])\n",
    "    activated_iids = []\n",
    "    for r in activated_iids_rows:\n",
    "        activated_iids.append(r[0])\n",
    "\n",
    "    # Get the remote folders at source input folder\n",
    "    src_input_folder_paths_regex = f\"{src_wf_root_path}/{src_input_folder_prefix}/*\"\n",
    "    rid = fxc.run(src_input_folder_paths_regex,\n",
    "                  endpoint_id=daq_fx_endpoint,\n",
    "                  function_id=fx_func_get_folder_paths_uuid)\n",
    "    src_input_folder_paths = automate_helper.fx_get_result(rid, fxc, delay=wf_config['funcx_req_delay'])\n",
    "\n",
    "    iids = []\n",
    "    for src_input_folder_path in src_input_folder_paths:\n",
    "        iid = re.findall(r'\\d+', src_input_folder_path)\n",
    "        if int(iid[-1]) > add_larger_than:\n",
    "            iids.append(iid[-1])\n",
    "        else: continue\n",
    "\n",
    "\n",
    "    # Get the remote folders at source output folder\n",
    "    src_output_folder_paths_regex = f\"{src_wf_root_path}/{src_output_folder_prefix}/*\"\n",
    "    rid = fxc.run(src_output_folder_paths_regex,\n",
    "                  endpoint_id=daq_fx_endpoint,\n",
    "                  function_id=fx_func_get_folder_paths_uuid)\n",
    "    ex_src_output_folder_paths = automate_helper.fx_get_result(rid, fxc, delay=wf_config['funcx_req_delay'])\n",
    "\n",
    "    oiids = []\n",
    "    for ex_src_output_folder_path in ex_src_output_folder_paths:\n",
    "        oiid = re.findall(r'\\d+', ex_src_output_folder_path)\n",
    "        if int(oiid[-1]) > add_larger_than: \n",
    "            oiids.append(oiid[-1])\n",
    "        else: continue\n",
    "\n",
    "    # Find the iids that need to be processed\n",
    "    diff_iids = []\n",
    "    for iid in iids:\n",
    "        if (int(iid)>add_larger_than) and (iid not in oiids) and (iid not in activated_iids): \n",
    "            diff_iids.append(iid) # process only these\n",
    "    \n",
    "    # If there is no scan to be processed sleep and then recheck \n",
    "    if(len(diff_iids)==0):\n",
    "        logging.debug(f\"There is no folder to be processed, \"\n",
    "                      f\"sleeping {wf_config['data_generation_delay']} secs.\")\n",
    "        time.sleep(wf_config['data_generation_delay'])\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # There are scans to be processed \n",
    "    fsrc_input_folder_paths = []\n",
    "    src_input_pos_files = []\n",
    "    src_output_folder_paths = []\n",
    "    dest_output_folder_paths = []\n",
    "    dest_input_folder_paths = []\n",
    "    dest_input_pos_files = []\n",
    "    iids = []\n",
    "    for src_input_folder_path in src_input_folder_paths[:-1]:\n",
    "        iid = re.findall(r'\\d+', src_input_folder_path)\n",
    "\n",
    "        # Skip if iid is already activated or processed\n",
    "        if (iid[-1] not in diff_iids): continue\n",
    "\n",
    "        iids.append(iid[-1])\n",
    "        fsrc_input_folder_paths.append(src_input_folder_path)\n",
    "        src_input_pos_files.append(f\"{src_wf_root_path}/{src_input_pos_folder_prefix}/fly{iid[-1]}_0.txt\")\n",
    "        src_output_folder_path = f\"{src_wf_root_path}/{src_output_folder_prefix}/{iid[-1]}\"\n",
    "        src_output_folder_paths.append(src_output_folder_path)\n",
    "        dest_input_folder_path = f\"{dest_wf_root_path}/{dest_input_folder_prefix}/{iid[-1]}\"\n",
    "        dest_input_folder_paths.append(dest_input_folder_path)\n",
    "        dest_input_pos_files.append(f\"{dest_input_folder_path}/fly{iid[-1]}_0.txt\")\n",
    "        dest_output_folder_path = f\"{dest_wf_root_path}/{dest_output_folder_prefix}/{iid[-1]}\"\n",
    "        dest_output_folder_paths.append(dest_output_folder_path)\n",
    "\n",
    "    src_input_folder_paths = fsrc_input_folder_paths\n",
    "\n",
    "    iids.reverse()\n",
    "    src_input_folder_paths.reverse()\n",
    "    src_input_pos_files.reverse()\n",
    "    src_output_folder_paths.reverse()\n",
    "    dest_input_folder_paths.reverse()\n",
    "    dest_input_pos_files.reverse()\n",
    "    dest_output_folder_paths.reverse()\n",
    "\n",
    "    for (iid, src_input_folder_path, src_input_pos_file, src_output_folder_path, \n",
    "        dest_input_folder_path, dest_input_pos_file, dest_output_folder_path ) in zip(iids, \n",
    "        src_input_folder_paths, src_input_pos_files, src_output_folder_paths, \n",
    "        dest_input_folder_paths, dest_input_pos_files, dest_output_folder_paths):\n",
    "        logging.debug(f\"{iid}: Source input folder: {src_input_folder_path}; \"\n",
    "                      f\"Source position file: {src_input_pos_file}; \"\n",
    "                      f\"Source output folder: {src_output_folder_path}\")\n",
    "        logging.debug(f\"Dest. input folder: {dest_input_folder_path}; \"\n",
    "                      f\"Dest. position file: {dest_input_pos_file}; \"\n",
    "                      f\"Dest. output folder: {dest_output_folder_path}\")\n",
    "    \n",
    "    if(len(iids)>0):\n",
    "        logging.debug(f\"All iids:{iids}\\n\"\n",
    "                        f\"Processed iids from output folder:{oiids}\\n\"\n",
    "                        f\"Currently/actively being processed iids:{activated_iids}\\n\"\n",
    "                        f\"Process scans with iid>{add_larger_than}\\n\"\n",
    "                        f\"To be processed iids:{diff_iids}\")\n",
    "    ### End of folder generation ###\n",
    "    \n",
    "      \n",
    "    ### Ptycho recon params setting up ###\n",
    "    flow_inputs = []\n",
    "    gcounter = 0\n",
    "    for (iid, src_input_folder_path, src_input_pos_file, src_output_folder_path,\n",
    "         dest_input_folder_path, dest_input_pos_file, dest_output_folder_path ) in zip(iids,\n",
    "        src_input_folder_paths, src_input_pos_files, src_output_folder_paths,\n",
    "        dest_input_folder_paths, dest_input_pos_files, dest_output_folder_paths):\n",
    "\n",
    "        flow_input = {\n",
    "            \"iid\" : iid,\n",
    "            \"input\": {\n",
    "                \"source_endpoint\": f\"{src_endpoint}\",\n",
    "                \"source_path\": f\"{src_input_folder_path}/\",\n",
    "                \"source_pos_path\": f\"{src_input_pos_file}\",\n",
    "                \"dest_endpoint\": dest_endpoint,\n",
    "                \"dest_path\": f\"{dest_input_folder_path}/\",\n",
    "                \"dest_pos_path\": dest_input_pos_file,\n",
    "\n",
    "                \"result_path\": f\"{dest_output_folder_path}\",\n",
    "                \"source_result_path\": f\"{src_output_folder_path}\",\n",
    "                \"fx_ep\": f\"{compute_fx_endpoint}\",\n",
    "                \"fx_id\": f\"{func_ptycho_uuid}\",\n",
    "                \"params\": {'ifpath': f\"{dest_input_folder_path}/fly{iid}_master.h5\",\n",
    "                           'ofpath': f\"{dest_output_folder_path}/\",\n",
    "                           'position_path': dest_input_pos_file,\n",
    "                           'script_path': task_config['executable']['script_path'],\n",
    "                           'python_path': task_config['python_path'],\n",
    "                           **exec_params_config,\n",
    "                           'sample_name': wf_config['flow']['sample_name'],\n",
    "                           'wid':gcounter}\n",
    "            }\n",
    "        }\n",
    "        gcounter+=1\n",
    "        flow_inputs.append(flow_input)\n",
    "        ### End of parameter setup\n",
    "    \n",
    "    logging.info(f\"Flows to be generated: {[finputs['iid'] for finputs in flow_inputs]}\\n\"\n",
    "                 f\"Total number of flows to be generated: {len(flow_inputs)}\")\n",
    "    \n",
    "    ### Initiate Flow ###\n",
    "    q1 = deque()\n",
    "    for i in range(len(flow_inputs)):\n",
    "        flow_action = flows_client.run_flow(flow_id, flow_scope, flow_inputs[i])\n",
    "        q1.append(flow_action)\n",
    "        executor_helper.append_activated_iids([flow_inputs[i]['iid']], wf_config['executor']['activated_iids_file_path'])\n",
    "        logging.info(f\"Flow {i} initiated and added to q1: {flow_action['action_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cancel all flows\n",
    "for flow_action in q1:\n",
    "    flows_client.flow_action_cancel(flow_id, flow_scope, flow_action['action_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
